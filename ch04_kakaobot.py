from fastapi import Request, FastAPI
from fastapi.responses import JSONResponse
from typing import Dict, Any
import os
import asyncio

# âœ… OpenAI ìµœì‹  SDK import ë°©ì‹ (ë²„ì „ í˜¸í™˜ ì•ˆì „)
try:
    from openai import OpenAI
except Exception:
    # êµ¬ë²„ì „ í˜¸í™˜ (ë§Œì•½ í•„ìš” ì‹œ)
    import openai
    OpenAI = openai.OpenAI  # type: ignore

# ====== í™˜ê²½ ë³€ìˆ˜ ======
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ====== ì„±ëŠ¥/ì•ˆì „ ì„¤ì • ======
OPENAI_TIMEOUT = 2.5   # OpenAI í˜¸ì¶œ ìì²´ íƒ€ì„ì•„ì›ƒ
ASYNC_TIMEOUT  = 2.8   # ì¹´ì¹´ì˜¤ê°€ ëŠê¸°ê¸° ì „ì— ìš°ë¦¬ ìª½ì—ì„œ fallback
MAX_TOKENS     = 200   # ì‘ë‹µ ì§§ê²Œ â†’ ì†ë„ ê°œì„ 
TEMPERATURE    = 0.5   # ë³€ë™ì„± ë‚®ì¶° ì¼ê´€ì„±/ì†ë„ í–¥ìƒ

client = OpenAI(api_key=API_KEY)
app = FastAPI()

# ====== ì „ì—­ ìºì‹œ & ë½ (ì„¸ì…˜ë³„ ê²°ê³¼ ì €ì¥ + ê²½í•© ë°©ì§€) ======
result_cache: Dict[str, Dict[str, Any]] = {}
cache_lock = asyncio.Lock()

# ====== ê³µí†µ í¬ë§· ======
def textResponseFormat(bot_response: str, quick: bool = False) -> Dict[str, Any]:
    payload = {
        "version": "2.0",
        "template": {
            "outputs": [{"simpleText": {"text": bot_response}}],
            "quickReplies": []
        }
    }
    if quick:
        payload["template"]["quickReplies"] = [
            {"action": "message", "label": "ì‹œê°„í‘œ ë³´ê¸°", "messageText": "ì‹œê°„í‘œ"},
            {"action": "message", "label": "ê¸‰ì‹ ë³´ê¸°", "messageText": "ê¸‰ì‹"},
            {"action": "message", "label": "ì¼ì • ë³´ê¸°", "messageText": "ì¼ì •"},
        ]
    return payload

def imageResponseFormat(img_url: str, prompt: str) -> Dict[str, Any]:
    output_text = f"{prompt} ë‚´ìš©ì— ê´€í•œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤."
    return {
        "version": "2.0",
        "template": {
            "outputs": [{"simpleImage": {"imageUrl": img_url, "altText": output_text}}],
            "quickReplies": []
        }
    }

def timeover() -> Dict[str, Any]:
    """ì¹´ì¹´ì˜¤ íƒ€ì„ì•„ì›ƒ ì „ì— ë¨¼ì € ë³´ë‚´ëŠ” ì„ì‹œ ì‘ë‹µ"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [{
                "simpleText": {
                    "text": "ì•„ì§ ì œê°€ ìƒê°ì´ ëë‚˜ì§€ ì•Šì•˜ì–´ìš” ğŸ™\nì ì‹œ í›„ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ í™•ì¸í•´ ì£¼ì„¸ìš”."
                }
            }],
            "quickReplies": [{
                "action": "message",
                "label": "ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”? ğŸ™‹",
                "messageText": "ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?"
            }]
        }
    }

# ====== GPT / DALLE í˜¸ì¶œ ======
def getTextFromGPT(user_text: str) -> str:
    """ë™ê¸° í˜¸ì¶œ (OpenAI SDK ë‚´ë¶€ëŠ” HTTP I/O), timeoutìœ¼ë¡œ ê³¼ë„ ì§€ì—° ë°©ì§€"""
    messages_prompt = [
        {
            "role": "system",
            "content": (
                "You are a thoughtful assistant who answers clearly and accurately in Korean. "
                "If the user asks you to speak informally (ë°˜ë§), respond in ë°˜ë§ style. "
                "Keep answers concise but complete. Avoid hallucination and check facts carefully. "
                "If asked who made you, answer 'ì´ì‹œí—Œ' made you."
            )
        },
        {"role": "user", "content": user_text}
    ]
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=messages_prompt,
            max_tokens=MAX_TOKENS,
            temperature=TEMPERATURE,
            timeout=OPENAI_TIMEOUT,  # âœ… í•µì‹¬: OpenAI í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ
        )
        return resp.choices[0].message.content or "ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        print("âŒ GPT í˜¸ì¶œ ì˜¤ë¥˜:", e)
        return "ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

def getImageURLFromDALLE(prompt: str) -> str | None:
    try:
        resp = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024",
            n=1,
            timeout=OPENAI_TIMEOUT,  # âœ… ì´ë¯¸ì§€ ìƒì„±ë„ ì œí•œ
        )
        return resp.data[0].url if resp and resp.data else None
    except Exception as e:
        print("âŒ DALLÂ·E ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜:", e)
        return None

# ====== ë¹„ë™ê¸° ì‘ì—… (ì¹´ì¹´ì˜¤ ì‘ë‹µì„ ë¨¼ì € ë³´ë‚´ê³  ë’¤ì—ì„œ ì²˜ë¦¬) ======
async def process_gpt_request(prompt: str, session_id: str):
    try:
        # OpenAI ë™ê¸° í˜¸ì¶œì„ ìŠ¤ë ˆë“œí’€ë¡œ ëŒë ¤ì„œ ì´ë²¤íŠ¸ë£¨í”„ ë¸”ë¡œí‚¹ ë°©ì§€
        loop = asyncio.get_running_loop()
        result_text = await loop.run_in_executor(None, getTextFromGPT, prompt)
        formatted = textResponseFormat(result_text, quick=True)
    except Exception as e:
        print("âŒ process_gpt_request ì˜ˆì™¸:", e)
        formatted = textResponseFormat("ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", quick=True)

    async with cache_lock:
        result_cache[session_id] = formatted

async def process_dalle_request(prompt: str, session_id: str):
    try:
        loop = asyncio.get_running_loop()
        img_url = await loop.run_in_executor(None, getImageURLFromDALLE, prompt)
        if img_url:
            formatted = imageResponseFormat(img_url, prompt)
        else:
            formatted = textResponseFormat("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš” ğŸ˜¢", quick=True)
    except Exception as e:
        print("âŒ process_dalle_request ì˜ˆì™¸:", e)
        formatted = textResponseFormat("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš” ğŸ˜¢", quick=True)

    async with cache_lock:
        result_cache[session_id] = formatted

# ====== FastAPI ì—”ë“œí¬ì¸íŠ¸ ======
@app.get("/")
async def root():
    return {"message": "kakaobot alive"}

@app.post("/chat/")
async def chat(request: Request):
    try:
        kakaorequest = await request.json()
        utterance = kakaorequest.get("userRequest", {}).get("utterance", "").strip()
        session_id = kakaorequest.get("userRequest", {}).get("user", {}).get("id", "")

        if not session_id:
            # ì¹´ì¹´ì˜¤ì—ì„œ idê°€ ë¹„ì–´ì˜¤ëŠ” ì˜ˆì™¸ ë°©ì§€
            session_id = kakaorequest.get("userRequest", {}).get("utterance", "")[:32]

        print("ğŸ—£ ì‚¬ìš©ì ë°œí™”:", utterance)

        # /ask
        if utterance.startswith("/ask"):
            prompt = utterance.replace("/ask", "", 1).strip()
            # âœ… ì¹´ì¹´ì˜¤ íƒ€ì„ì•„ì›ƒ ì „ì— ì„ì‹œì‘ë‹µ ë³´ë‚´ê³ , ë’¤ì—ì„œ ì²˜ë¦¬
            asyncio.create_task(asyncio.wait_for(process_gpt_request(prompt, session_id), timeout=ASYNC_TIMEOUT))
            return JSONResponse(content=timeover())

        # /img
        if utterance.startswith("/img"):
            prompt = utterance.replace("/img", "", 1).strip()
            asyncio.create_task(asyncio.wait_for(process_dalle_request(prompt, session_id), timeout=ASYNC_TIMEOUT))
            return JSONResponse(content=timeover())

        # "ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?"
        if "ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?" in utterance:
            async with cache_lock:
                result = result_cache.pop(session_id, None)
            if result:
                return JSONResponse(content=result)
            # ì•„ì§ ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ ê¸°ë³¸ ê°€ì´ë“œ ì œê³µ
            return JSONResponse(content=textResponseFormat("ì•„ì§ ê²°ê³¼ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì–´ìš” ğŸ˜¢ ì ì‹œ í›„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.", quick=True))

        # ê¸°ë³¸ ì‘ë‹µ
        return JSONResponse(content=textResponseFormat("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š", quick=True))

    except asyncio.TimeoutError:
        # ë¹„ë™ê¸° ì²˜ë¦¬ ìì²´ê°€ ì œí•œì‹œê°„ì„ ì´ˆê³¼
        return JSONResponse(content=textResponseFormat("ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", quick=True))

    except Exception as e:
        print("âŒ ì „ì²´ í•¸ë“¤ëŸ¬ ì˜ˆì™¸:", e)
        return JSONResponse(
            content=textResponseFormat("ì„œë²„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."),
            status_code=500
        )
